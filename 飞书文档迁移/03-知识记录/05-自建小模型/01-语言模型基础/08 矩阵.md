---
created: '2025-03-21 15:25:43'
feishu_url: https://wk5tnvpfe7.feishu.cn/docx/Oj8Mdod3xouXPPx8IoLcDsmlnvh
modified: '2025-03-21 16:23:22'
source: feishu
title: 08 矩阵
---

08 矩阵
矩阵乘法的过程
背景：有两个矩阵
输入矩阵 X，代表每个学生的成绩，维度是 3×3（3 个学生，3 门课）：
  
权重矩阵 W，维度是 3×1（每门课的权重）： 
 
这个矩阵表示每个科目的权重：数学、英语、科学。
目标：通过矩阵乘法，计算每个学生的加权平均分
也就是说，我们想要计算每个学生在数学、英语和科学成绩上的加权平均。
步骤：矩阵乘法
矩阵乘法的基本规则是：行 × 列，也就是说，矩阵 X 的每一行（每个学生的成绩）会和 矩阵 W 的每一列（每个科目的权重）进行乘法运算并求和。
我们可以一行一行地计算，举个例子：
第一行（学生 1）：
学生 1 的成绩是 [80, 90, 85]，我们用这个成绩和权重矩阵 W 进行乘法运算：
 
计算得到：
 
将这些加起来：
 
所以，学生 1 的加权平均分是 85.05。
第二行（学生 2）：
学生 2 的成绩是 [75, 85, 95]，用相同的方式计算：
 
计算得到：
 
加起来：
 
所以，学生 2 的加权平均分是 85.05。
第三行（学生 3）：
 学生 3 的成绩是 [90, 88, 80]，同样计算：
 
计算得到：
 
加起来：
 
所以，学生 3 的加权平均分是 86.94。
2. 结果：
通过矩阵乘法，计算得到的加权平均分如下：
 
这就是我们想要的每个学生的加权平均分。

总结：
矩阵乘法通过将每个学生的成绩和权重矩阵进行逐个元素的乘法并求和，快速地得到每个学生的加权平均分。
这种方法比逐个计算每个学生的加权平均更加高效，特别是在有大量数据时。
形象解释：矩阵相乘是怎么回事？
可以把 input_data（1×2 矩阵）想象成一个人的考试成绩，有两个科目，比如 数学（5 分） 和 语文（3 分）。
而 W（2×5 矩阵）就像是一群老师，他们分别对这两个科目的表现进行评分，并且每个老师关注不同的能力点（比如逻辑思维、表达能力、创造力等 5 个方面）。
每个老师会根据数学和语文的成绩，按照不同的权重来打分。最终，每个老师都会给出自己的综合评分。

具象比喻
假设有 5 位老师（对应隐藏层 5 个神经元），他们对数学和语文的评分标准不同（权重 W），计算过程如下：



ReLU 激活（非线性转换）
有的老师可能给出负分（-0.3），但是负分没有意义（比如创造力不能是负的）。这时候，我们用 ReLU（负分变 0，正分不变），所以最终得分变成：


🎯 通俗解释：你考了数学 5 分、语文 3 分，每个老师会用不同的标准打分，最后给你 5 个方面的评分。负的评分没意义（用 ReLU 变成 0），这样就得到最终的隐藏层输出。
这样，隐藏层的 5 维向量就可以作为下一步计算的输入了！ 🚀
2×5 矩阵（权重矩阵 W）的来源：它是怎么来的？
简单来说，2×5 的权重矩阵 W 是模型「学习」出来的，而不是人为设定的。
在神经网络的初始状态，权重是随机初始化的，然后通过训练数据不断调整，使得最终的模型可以准确预测输入数据的输出。

1️⃣ 直观理解：权重矩阵是什么？
可以把 W 想象成一个新人老师的评分标准，一开始并不准确，需要在大量考试数据中慢慢调整，直到给分合理。

这些 ? 就是随机初始化的权重参数，一开始是随意的。
但随着训练，模型会不断调整权重，让计算出来的结果更接近真实值。

2️⃣ 训练过程中权重怎么调整？
神经网络会使用梯度下降和反向传播算法，不断更新 W，让它变得更合理。
 整个过程可以分为以下步骤：
(1) 初始化权重
训练前，权重 W 的每个数值是随机的，比如：
   
这些初始值是随机生成的，可能并不合适。

(2) 计算输出（前向传播）
假设输入是：
 
根据矩阵乘法：
 
得到初始的预测值。

(3) 计算误差
模型会对比预测值和真实值，计算误差（Loss），比如：
 

(4) 反向传播调整权重
神经网络通过反向传播（backpropagation），计算 W 对误差的影响，并用梯度下降（Gradient Descent）来更新 W：
 
其中：
α 是学习率（learning rate），控制调整的步伐。
∂Loss/∂W 代表权重对损失的影响，即梯度。
这个过程会重复多次，直到 W 变得足够好，使得预测结果足够接近真实值。

3️⃣ 通俗比喻：训练是如何优化权重的？
可以把 W 想象成一个新手老师的评分标准，刚开始评分标准很随意，但随着时间推移，老师会通过大量考试成绩的数据来不断优化评分方式。
初始阶段（随机初始化）：
老师随意打分，分数可能很离谱，比如语文高的被认为计算能力强。
训练阶段（反向传播优化）：
发现评分有误，逐步调整，比如语文好的人不一定计算能力强，数学高分的人更可能计算能力强。
最终（训练收敛）：
老师的评分标准越来越合理，最后可以准确评估每个学生的能力。

4️⃣ 总结
✅ 2×5 的权重矩阵 W 是怎么来的？
初始化时是随机的，没有什么特别规律。
训练时通过误差反馈不断优化，调整 W 使预测更准确。
✅ 为什么要训练权重？
让网络自动学习合适的特征权重，而不是手动设定规则。
让模型能够泛化，适用于不同的数据，而不仅仅是死记硬背。
✅ 简单比喻
W 就像一个评分标准，训练的过程就是不断调整评分方法，使其更加合理！ 🚀

